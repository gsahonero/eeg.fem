{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Intro"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook we process all the data for the 4 base models:\r\n",
    "1. Data - Filters (theta, alpha, beta) - Window 64 data ((14x3x64)+1 = 2688 features) for SVM (RBF and Linear)\r\n",
    "2. Data - Filters (theta, alpha, beta) - Window 128 data ((14x3x128)+1 = 5377 features) for SVM (RBF and Linear)\r\n",
    "3. Data - Filters (theta, alpha, beta) - Window 64 data (14x3x64 = 2688 features) - PSD signal properties (14x3x6 = 252 features) for SVM (RBF and Linear)\r\n",
    "4. Data - Filters (theta, alpha, beta) - Window 64 data (14x3x64 = 2688 features) - MaxMinScaler (to transform all from 0 to 1) - PCA (data reduction to half ((2688/2)+1 = 1345 features)) for SVM (RBF and Linear)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0.1 Import all the packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import scipy.signal as signal\r\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data - Filters (theta, alpha, beta) - Window 64 data ((14x3x64)+1 = 2688 features) for SVM (RBF and Linear)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1. This function is for a and b parameters for the filters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def param(N, Wn, fs):\r\n",
    "    b, a = signal.butter(N, Wn, btype='bandpass', analog=False, output='ba', fs=fs)\r\n",
    "    return a, b"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 This function is to filter all the signals in the 3 bands (Theta, Alpha and Theta) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def filt(df, a_th, b_th, a_al, b_al, a_be, b_be, path, CI, tp, num):\r\n",
    "    x_th = np.zeros(df.shape)\r\n",
    "    x_al = np.zeros(df.shape)\r\n",
    "    x_be = np.zeros(df.shape)\r\n",
    "    y = df[:,14]\r\n",
    "    for i in range(df.shape[1]):\r\n",
    "        x_th[:, i] = signal.filtfilt(b_th, a_th, df[:, i])\r\n",
    "        x_al[:, i] = signal.filtfilt(b_al, a_al, df[:, i])\r\n",
    "        x_be[:, i] = signal.filtfilt(b_be, a_be, df[:, i])\r\n",
    "    x_th[:,14] = y\r\n",
    "    x_al[:,14] = y\r\n",
    "    x_be[:,14] = y\r\n",
    "    return x_th, x_al, x_be"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Here we order the filtered signal acording the 64 data windowing making the 2687 features and adding the preview class, in total 2689 features. This function can do the windowing of the value of `win`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def dat_prep_win(x_th, x_al, x_be, df, base_l1, base_l2, win, jump, fs, tp, num, path, CI):\r\n",
    "    if df[0, 14] == 5:\r\n",
    "        base = int(base_l2*fs)\r\n",
    "    else:\r\n",
    "        base = int(base_l1*fs)\r\n",
    "\r\n",
    "    shape = int(df.shape[0]-(base*2))\r\n",
    "\r\n",
    "    X_shape1 = (14*3*win)+2\r\n",
    "    X_shape0 = int((shape-win)/jump)+1\r\n",
    "    X = np.empty((X_shape0, X_shape1))\r\n",
    "    jump_to = 0\r\n",
    "    for i in range(X_shape0):\r\n",
    "        p = 0 \r\n",
    "        for j in range(win):\r\n",
    "            to_p = p\r\n",
    "            p += 1\r\n",
    "            X[i, (14*to_p):(14*p)] = x_th[base+jump_to+j, :14]\r\n",
    "            to_p = p\r\n",
    "            p += 1\r\n",
    "            X[i, (14*to_p):(14*p)] = x_al[base+jump_to+j, :14]\r\n",
    "            to_p = p\r\n",
    "            p += 1\r\n",
    "            X[i, (14*to_p):(14*p)] = x_be[base+jump_to+j, :14]\r\n",
    "        X[i, X_shape1-2] = df[base+jump_to, 14]\r\n",
    "        X[i, X_shape1-1] = df[base+jump_to, 14]\r\n",
    "        jump_to += jump\r\n",
    "    return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Here we join the classes 1 and 2 in 1, the class 3 and 4 in 2 and the class 5 in 3, to have only 3 classes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def five_to_three_class(X, win):\r\n",
    "    y_new = np.empty((X.shape[0],2))\r\n",
    "    y_new = X[:, (win*3*14):]\r\n",
    "    y_new = np.where(y_new == 2, int(1), y_new)   #La clase 2 lo cambiamos a 1\r\n",
    "    y_new = np.where(y_new == 4, int(3), y_new)   #La clase 4 lo cambiamos a 3\r\n",
    "    y_new = np.where(y_new == 3, int(2), y_new)   #La clase 3 lo cambiamos a 2\r\n",
    "    y_new = np.where(y_new == 5, int(3), y_new)   #La clase 5 lo cambiamos a 3\r\n",
    "\r\n",
    "    X[:, (win*3*14):] = y_new\r\n",
    "    return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.6 This function run all the process."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def main_func(win, base_l1, base_l2, jump, fs, N, path, CI):\r\n",
    "    X_5C = np.empty((0,(win*3*14) + 2))\r\n",
    "    X = np.empty((0,(win*3*14) + 2))\r\n",
    "    a_th, b_th = param(N=N, Wn=[4, 7], fs=fs)\r\n",
    "    a_al, b_al = param(N=N, Wn=[8, 12], fs=fs)\r\n",
    "    a_be, b_be = param(N=N, Wn=[12, 30], fs=fs)\r\n",
    "    for i in range(1, 9):\r\n",
    "        for j in range(1, 8):\r\n",
    "            df = np.genfromtxt(str(path)+'/'+str(CI)+'/data_clean_per_session/'+'Type_'+str(i)+'_'+str(j)+'.csv',dtype=float,delimiter=',',skip_header=1)\r\n",
    "            x_th, x_al, x_be = filt(df=df, a_th=a_th, b_th=b_th, a_al=a_al, b_al=b_al, a_be=a_be, b_be=b_be, path=path, CI=CI, tp=i, num=j)\r\n",
    "            x_append = dat_prep_win(x_th=x_th, x_al=x_al, x_be=x_be, df=df, base_l1=base_l1, base_l2=base_l2, win=win, jump=jump, fs=fs, tp=j, num=i, path=path, CI=CI)\r\n",
    "            X_5C = np.append(X_5C, x_append, axis=0)\r\n",
    "    X_3C = five_to_three_class(X=X_5C, win=win)\r\n",
    "    print('Data_prep_'+str(win)+'_'+str(CI)+': Done')\r\n",
    "    return X_3C"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7 Here we define all the important values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "win = 64\r\n",
    "base_l1 = 5\r\n",
    "base_l2 = 2.5\r\n",
    "jump = 16\r\n",
    "fs = 256\r\n",
    "N = 6\r\n",
    "path = 'D:/Github/eeg.fem/public/data/Musical'\r\n",
    "CI = 5956733"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.8 Start to make the data processing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_64 = main_func(win, base_l1, base_l2, jump, fs, N, path, CI)\r\n",
    "np.savetxt(str(path)+'/'+str(CI)+'/data_for_train/ALL_3C_'+str(win)+'.csv', X_64, delimiter=',')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data_prep_64_5956733: Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data - Filters (theta, alpha, beta) - Window 128 data ((14x3x128)+1 = 5377 features) for SVM (RBF and Linear)\r\n",
    "For this data preparation we will use all the functions we saw before, so we have to set up all the variables. We have do define the steps *1.7* and run *1.8*."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Declaring variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "win = 128\r\n",
    "base_l1 = 5\r\n",
    "base_l2 = 2.5\r\n",
    "jump = 16\r\n",
    "fs = 256\r\n",
    "N = 6\r\n",
    "path = 'D:/Github/eeg.fem/public/data/Musical'\r\n",
    "CI = 5956733"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Running all the preprossesing data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "X_128 = main_func(win, base_l1, base_l2, jump, fs, N, path, CI)\r\n",
    "np.savetxt(str(path)+'/'+str(CI)+'/data_for_train/ALL_3C_'+str(win)+'.csv', X_128, delimiter=',')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data_prep_128_5956733: Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Data - Filters (theta, alpha, beta) - Window 64 data (14x3x64 = 2688 features) - PSD signal properties (14x3x6 = 252 features) for SVM (RBF and Linear)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 For this data pre we are going to start from the output of the first model. So we going to declare the variables like the first data pre."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "win = 64\r\n",
    "base_l1 = 5\r\n",
    "base_l2 = 2.5\r\n",
    "jump = 16\r\n",
    "fs = 256\r\n",
    "N = 6\r\n",
    "path = 'D:/Github/eeg.fem/public/data/Musical'\r\n",
    "CI = 5956733"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 We are going to run the step *1.8*."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "X_64 = main_func(win, base_l1, base_l2, jump, fs, N, path, CI)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data_prep_64_5956733: Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 From here we are going to create the function to preform the Power Spectral Density."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def psd_X(X, win, path, CI, fs):\r\n",
    "    #Get m,n data.shape\r\n",
    "    m, n = X.shape\r\n",
    "    #Create the new_data matrix\r\n",
    "    new_data = np.empty((X.shape[0],((6*14*3)+2)))\r\n",
    "    x = np.empty((1, ((6*14*3)+2)))\r\n",
    "    #Recorremos de i -> m\r\n",
    "    for i in range(m):\r\n",
    "    #Recorremos de j -> 42 recoriendo cada electrodo de cada filtro (14*3)\r\n",
    "        l = 0\r\n",
    "        for j in range(42):\r\n",
    "            d_a = j\r\n",
    "    #Recorremos la cantidad de win k -> win que es el window\r\n",
    "            for k in range(win):\r\n",
    "    #Ponemos en los indices x[0, k] = X[i, d_a]\r\n",
    "                x[0, k] = X[i, d_a]\r\n",
    "                d_a += 42\r\n",
    "    #Sacamos las propiedades cada señal\r\n",
    "            new_data[i, l] = np.amax(x) #Maximo valor en x\r\n",
    "            new_data[i, l+1] = np.amin(x)   #Minimo valor en x\r\n",
    "            new_data[i, l+2] = np.amax(x)-np.amin(x)    #Diferencia entre max y min\r\n",
    "            new_data[i, l+3] = np.mean(x) #Valor promedio\r\n",
    "            new_data[i, l+4] = np.sum(np.power(x, 2)/((win*1000)/fs))  #Power spectral density in ms\r\n",
    "            new_data[i, l+5] = np.sum(np.power(x, 2))   #Energy spectral density\r\n",
    "            l = l+6\r\n",
    "    new_data[:, -2:] = X[:, -2:] #Ponemos old_y y y en los nuevos datos.\r\n",
    "    print('PSD_Done')\r\n",
    "    return new_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4 Now we run the PSD function and save it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X_psd = psd_X(X=X_64, win=win, path=path, CI=CI, fs=fs)\r\n",
    "np.savetxt(str(path)+'/'+str(CI)+'/data_for_train/ALL_PSD_'+str(win)+'.csv', X_psd, delimiter=',')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PSD_Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Data - Filters (theta, alpha, beta) - Window 64 data (14x3x64 = 2688 features) - MaxMinScaler (to transform all from 0 to 1) - PCA (data reduction to half ((2688/2)+1 = 1345 features)) for SVM (RBF and Linear)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1 In this function we determine the maximun and minimun values of each signal, this function return one matrix of (14, 6), in the raws we have the 14th electrodes and in the columns we have the max and min of each band of the electrode (theta, alpha and beta). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def param_max_min(fil_max_min, i, j, x_th, x_al, x_be):\r\n",
    "    if i == 1 and j == 1:\r\n",
    "        for a in range(14):\r\n",
    "            fil_max_min[a,0] = np.amax(x_th[1:,a])\r\n",
    "            fil_max_min[a,1] = np.amin(x_th[1:,a])\r\n",
    "            fil_max_min[a,2] = np.amax(x_al[1:,a])\r\n",
    "            fil_max_min[a,3] = np.amin(x_al[1:,a])\r\n",
    "            fil_max_min[a,4] = np.amax(x_be[1:,a])\r\n",
    "            fil_max_min[a,5] = np.amin(x_be[1:,a])\r\n",
    "    else:\r\n",
    "        for a in range(14):\r\n",
    "            if fil_max_min[a, 0] < np.amax(x_th[1:, a]):\r\n",
    "                fil_max_min[a, 0] = np.amax(x_th[1:, a])\r\n",
    "            if fil_max_min[a, 1] > np.amin(x_th[1:, a]):\r\n",
    "                fil_max_min[a, 1] = np.amin(x_th[1:, a])\r\n",
    "            if fil_max_min[a, 2] < np.amax(x_al[1:, a]):\r\n",
    "                fil_max_min[a, 2] = np.amax(x_al[1:, a])\r\n",
    "            if fil_max_min[a, 3] > np.amin(x_al[1:, a]):\r\n",
    "                fil_max_min[a, 3] = np.amin(x_al[1:, a])\r\n",
    "            if fil_max_min[a, 4] < np.amax(x_be[1:, a]):\r\n",
    "                fil_max_min[a, 4] = np.amax(x_be[1:, a])\r\n",
    "            if fil_max_min[a, 5] > np.amin(x_be[1:, a]):\r\n",
    "                fil_max_min[a, 5] = np.amin(x_be[1:, a])\r\n",
    "    return fil_max_min"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 This function is the same as the `main_func` but this function adds the `fil_max_min` matrix, to determine this we use the `para_max_min` function, and returns `X_3C` and `fil_max_min` matrices."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def main_func_pca(win, base_l1, base_l2, jump, fs, N, path, CI):\r\n",
    "    X_5C = np.empty((0,(win*3*14) + 2))\r\n",
    "    X = np.empty((0,(win*3*14) + 2))\r\n",
    "    fil_max_min = np.empty((14, 6))\r\n",
    "    a_th, b_th = param(N=N, Wn=[4, 7], fs=fs)\r\n",
    "    a_al, b_al = param(N=N, Wn=[8, 12], fs=fs)\r\n",
    "    a_be, b_be = param(N=N, Wn=[12, 30], fs=fs)\r\n",
    "    for i in range(1, 9):\r\n",
    "        for j in range(1, 8):\r\n",
    "            df = np.genfromtxt(str(path)+'/'+str(CI)+'/data_clean_per_session/'+'Type_'+str(i)+'_'+str(j)+'.csv',dtype=float,delimiter=',',skip_header=1)\r\n",
    "            x_th, x_al, x_be = filt(df=df, a_th=a_th, b_th=b_th, a_al=a_al, b_al=b_al, a_be=a_be, b_be=b_be, path=path, CI=CI, tp=i, num=j)\r\n",
    "            fil_max_min = param_max_min(fil_max_min, i, j, x_th, x_al, x_be)\r\n",
    "            x_append = dat_prep_win(x_th=x_th, x_al=x_al, x_be=x_be, df=df, base_l1=base_l1, base_l2=base_l2, win=win, jump=jump, fs=fs, tp=j, num=i, path=path, CI=CI)\r\n",
    "            X_5C = np.append(X_5C, x_append, axis=0)\r\n",
    "    X_3C = five_to_three_class(X=X_5C, win=win)\r\n",
    "    print('Data_prep_'+str(win)+'_'+str(CI)+': Done')\r\n",
    "    return X_3C, fil_max_min"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 This functio scaled the data acording to the given `fil_max_min` matrix and returns the X_scaled, the feature `y_old` and `y` remains the same."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def scaled(X, fil_max_min, win):\r\n",
    "    X_scaled = np.empty((X.shape))\r\n",
    "    idx = np.empty((42,64))\r\n",
    "    for i in range (42):\r\n",
    "        w = i\r\n",
    "        for j in range(win):\r\n",
    "            idx[i,j] = w\r\n",
    "            w += 42\r\n",
    "    max_min = 0\r\n",
    "    k = 0\r\n",
    "    for i in range (3):\r\n",
    "        for j in range(14):\r\n",
    "            idx_list = idx[k,:].astype(int)\r\n",
    "            X_scaled[:, idx_list] = (X[:, idx_list]-fil_max_min[j,max_min+1])/(fil_max_min[j,max_min]-fil_max_min[j,max_min+1])\r\n",
    "            k += 1\r\n",
    "        max_min += 2\r\n",
    "    X_scaled[:,-2:] = X[:,-2:]\r\n",
    "    return X_scaled"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 In this function we apply PCA, the `y_old` feature doesnt enter to the PCA reduction."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def pca_X(X_scaled, n_comp, svd_solver, random_state):\r\n",
    "    pca = PCA(n_components=n_comp, svd_solver=svd_solver, random_state=random_state)\r\n",
    "    pca.fit(X_scaled[:,:-2])\r\n",
    "    X_pca_i = pca.transform(X_scaled[:,:-2])\r\n",
    "    X_pca = np.insert(X_pca_i, X_pca_i.shape[1], X_scaled[:, -2:].T, axis=1)\r\n",
    "    print(X_pca_i.shape)\r\n",
    "    print(X_pca.shape)\r\n",
    "    return X_pca"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 We start the PCA function with the MaxMin scaler and next the PCA."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def main_pca(win, base_l1, base_l2, jump, fs, N, path, CI, n_comp, svd_solver, random_state):\r\n",
    "    X, fil_max_min = main_func_pca(win, base_l1, base_l2, jump, fs, N, path, CI)\r\n",
    "    #Escalamos las funciones de 0 a 1\r\n",
    "    X_scaled = scaled(X, fil_max_min, win)\r\n",
    "    #Hacemos PCA\r\n",
    "    X_pca = pca_X(X_scaled, n_comp, svd_solver, random_state)\r\n",
    "    return X_pca, fil_max_min, X_scaled"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 We set up all the variables."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "win = 64\r\n",
    "base_l1 = 5\r\n",
    "base_l2 = 2.5\r\n",
    "jump = 16\r\n",
    "fs = 256\r\n",
    "N = 6\r\n",
    "path = 'D:/Github/eeg.fem/public/data/Musical'\r\n",
    "CI = 5956733\r\n",
    "n_comp = 10 #Number of components to be divided\r\n",
    "svd_solver = 'randomized' #PCA solver\r\n",
    "random_state = 21 #Random state of PCA solver"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.5 We run all the functions and save `X_pca` and the matrix `fil_max_min` were have all the max and min values of each channel of each filter."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "X_pca, fil_max_min, X_scaled = main_pca(win, base_l1, base_l2, jump, fs, N, path, CI, n_comp, svd_solver, random_state)\r\n",
    "np.savetxt(str(path)+'/'+str(CI)+'/data_for_train/ALL_PCA_'+str(win)+'.csv', X_pca, delimiter=',')\r\n",
    "np.savetxt(str(path)+'/'+str(CI)+'/data_for_train/ALL_3C_'+str(win)+'_scaled.csv', X_scaled[:n_comp,:-2], delimiter=',')\r\n",
    "np.savetxt(str(path)+'/'+str(CI)+'/ML_models/fil_max_min.csv', fil_max_min, delimiter=',')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data_prep_64_5956733: Done\n",
      "(6728, 10)\n",
      "(6728, 12)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('BCIMusical': conda)"
  },
  "interpreter": {
   "hash": "f9ecac2d14d2bb269a4709d9862e512850489fa6d8ba68695ffcc8a638687dcf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}